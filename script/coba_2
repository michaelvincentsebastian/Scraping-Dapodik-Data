import requests
from bs4 import BeautifulSoup
import re
import json
import csv
import time
import urllib3
import os
import sys

# Menonaktifkan peringatan SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- KONSTANTA GLOBAL ---
BASE_URL = 'https://dapo.kemendikdasmen.go.id'
SEMESTER_ID = '20251' # Ganti sesuai semester yang diinginkan
LEVEL_WILAYAH = '0'
KODE_WILAYAH = '000000'

# --- HELPER FUNCTIONS ---

def request_api(base_url: str = BASE_URL, level_wilayah: str = LEVEL_WILAYAH, kode_wilayah: str = KODE_WILAYAH, semester_id: str = SEMESTER_ID, sekolah_id: str = None) -> list:
    """
    Mengambil data wilayah atau rekapitulasi sekolah dari API Dapo.
    Jika terjadi error 404/500, ia langsung return list kosong (gaya kode pertama).
    """
    
    # Penentuan URL API
    if sekolah_id:
        # API untuk detail rekapitulasi sekolah
        url = f'{base_url}/rekap/sekolahDetail?semester_id={semester_id}&sekolah_id={sekolah_id}'
    elif level_wilayah == '4':
        # API untuk data Sekolah, kode_wilayah di sini sudah berisi kode_kecamatan + '&bentuk_pendidikan_id='
        url = f'{base_url}/rekap/dataSekolah?id_level_wilayah=4&kode_wilayah={kode_wilayah}&semester_id={semester_id}'
    else:
        # API untuk data wilayah (provinsi/kota/kecamatan)
        url = f'{base_url}/rekap/dataSekolah?id_level_wilayah={level_wilayah}&kode_wilayah={kode_wilayah}&semester_id={semester_id}'

    try:
        req = requests.get(url, timeout=15)
        
        if req.status_code == 200:
            if not req.text:
                return []
            return req.json()
        else:
            # Mengadopsi penanganan error dari kode pertama (fast fail)
            if level_wilayah == '4':
                 # Hanya cetak error untuk level sekolah agar tidak terlalu berisik di level wilayah
                 print(f"    [API ERROR] Status {req.status_code} for URL: {url}")
            return []
            
    except requests.exceptions.RequestException as e:
        # Error jaringan/timeout juga langsung gagal
        print(f"    [NETWORK ERROR] Gagal mengambil data dari {kode_wilayah}: {e}")
        return []

def request_html(url: str, backoff: float = 2.0) -> str:
    """Mengambil konten HTML dengan mekanisme retry sederhana."""
    # Mekanisme retry sederhana dipertahankan untuk HTML karena lebih krusial.
    for attempt in range(3): 
        try:
            if not url.startswith('http'):
                raise ValueError(f"Invalid URL: {url}")
            res = requests.get(url, verify=False, timeout=10) 
            if res.status_code == 404:
                return "" 
            
            if "User validation required" in res.text or "Checking your browser" in res.text:
                print(f"        [WARNING] Validasi Pengguna Ditemukan. Retrying in {backoff}s...")
                time.sleep(backoff)
                backoff *= 2 
                continue
            return res.text
        except requests.RequestException as e:
            print(f"        [NETWORK ERROR] {e}, retrying in {backoff}s...")
            time.sleep(backoff)
            backoff *= 2
    return ""

def lat_lon_parse(url: str):
    """Mengambil koordinat Lintang dan Bujur dari halaman referensi."""
    req = request_html(url)
    if not req: return None, None
    soup = BeautifulSoup(req, 'html.parser')
    latitude, longitude = None, None
    scripts = soup.find_all('script')
    for script in scripts:
        if script.string and "L.map('maps').setView" in script.string: 
            lat_search = re.search(r"lat:\s*(-?\d+\.\d+)", script.string)
            lon_search = re.search(r"lon:\s*(-?\d+\.\d+)", script.string)
            if lat_search: latitude = lat_search.group(1)
            if lon_search: longitude = lon_search.group(1)
            break
    return latitude, longitude

def parse_html(url: str):
    """Mengurai (parse) halaman HTML detail sekolah dan mengambil data profil/kontak/rekapitulasi."""
    req = request_html(url)
    school_data = {"profile": {}, "recapitulation": {}, "contact": {}}
    if not req:
         return json.dumps(school_data, ensure_ascii=False)
    
    soup = BeautifulSoup(req, 'html.parser')
    sidebar_data = {} 
    
    # 1. Mengambil data PROFIL & SIDEBAR
    profile_panels = soup.select('#profil .panel-info')
    for panel in profile_panels:
        heading = panel.find(class_='panel-heading').get_text(strip=True)
        body = panel.find(class_='panel-body')
        section_data = {}
        if body: 
             for p in body.find_all('p'):
                 if p.find('strong'):
                     key = p.find('strong').get_text(strip=True).replace(':', '').strip()
                     value = p.strong.next_sibling.strip() if p.strong.next_sibling else '' 
                     section_data[key] = value
             if "Identitas" in heading:
                 school_data["profile"]["identitas_sekolah"] = section_data
             elif "Pelengkap" in heading:
                 school_data["profile"]["data_pelengkap"] = section_data
             elif "Rinci" in heading:
                 school_data["profile"]["data_rinci"] = section_data

    sidebar_menu = soup.find(class_='profile-usermenu')
    if sidebar_menu:
        for item in sidebar_menu.find_all('li'):
            text = item.get_text(strip=True)
            if ':' in text:
                key, value = text.split(':', 1)
                sidebar_data[key.strip()] = value.strip()
    school_data["profile"]["sidebar_info"] = sidebar_data 

    # 2. Mengambil data KONTAK
    contact_panel = soup.select_one('#kontak .panel-info')
    if contact_panel:
        contact_info = {}
        for p in contact_panel.find_all('p'):
            if p.find('strong'):
                key = p.find('strong').get_text(strip=True).replace(':', '').strip()
                value = p.strong.next_sibling.strip() if p.strong.next_sibling else ''
                contact_info[key] = value
        school_data["contact"] = contact_info

    # 3. Mengambil Lintang/Bujur
    npsn = school_data["profile"].get("identitas_sekolah", {}).get("NPSN", "")
    if npsn:
        urls_latlon = f'https://referensi.data.kemdikbud.go.id/pendidikan/npsn/{npsn}'
        latitude, longitude = lat_lon_parse(urls_latlon)
        if latitude or longitude:
            school_data["contact"]["Lintang"] = latitude
            school_data["contact"]["Bujur"] = longitude

    # 4. Mengambil data REKAPITULASI (API Call)
    sekolah_id = url.split('/')[-1].strip()
    recapitulation_list = request_api(sekolah_id=sekolah_id)
    if recapitulation_list and isinstance(recapitulation_list, list) and len(recapitulation_list) > 0:
        school_data["recapitulation"] = recapitulation_list[0] 
    else:
        school_data["recapitulation"] = {}

    return json.dumps(school_data, indent=4, ensure_ascii=False)

def create_csv_header(filename):
    """Membuat file CSV baru dengan header."""
    headers = [
        'Nama_Sekolah', 'Provinsi', 'Kota', 'Kecamatan',
        'NPSN', 'Status', 'Bentuk_Pendidikan', 'Status_Kepemilikan',
        'SK_Pendirian_Sekolah', 'Tanggal_SK_Pendirian', 'SK_Izin_Operasional',
        'Tanggal_SK_Izin_Operasional', 'Kebutuhan_Khusus_Dilayani', 'Nama_Bank',
        'Cabang_KCP_Unit', 'Rekening_Atas_Nama', 'Status_BOS',
        'Waku_Penyelenggaraan', 'Sertifikasi_ISO', 'Sumber_Listrik',
        'Daya_Listrik', 'Kecepatan_Internet', 'Kepsek', 'Operator',
        'Akreditasi', 'Kurikulum', 'Waktu', 'Alamat', 'RT_RW',
        'Dusun', 'Desa_Kelurahan', 'Kecamatan_Detail', 'Kabupaten',
        'Provinsi_Detail', 'Kode_Pos', 'Lintang', 'Bujur', 'Guru_L', 'Guru_P', 'Guru_Total',
        'Tendik_L', 'Tendik_P', 'Tendik_Total', 'PTK_L', 'PTK_P', 'PTK_Total', 'PD_L', 'PD_P', 'PD_Total',
        'Before_Ruang_Kelas', 'After_Ruang_Kelas', 'Before_Ruang_Perpus', 'After_Ruang_Perpus',
        'Before_Ruang_Lab', 'After_Ruang_Lab', 'Before_Ruang_Pratik', 'After_Ruang_Pratik',
        'Before_Ruang_Pimpinan', 'After_Ruang_Pimpinan', 'Before_Ruang_Guru', 'After_Ruang_Guru',
        'Before_Ruang_Ibadah', 'After_Ruang_Ibadah', 'Before_Ruang_UKS', 'After_Ruang_UKS',
        'Before_Toilet', 'After_Toilet', 'Before_Gudang', 'After_Gudang',
        'Before_Ruang_Sirkulasi', 'After_Ruang_Sirkulasi', 'Before_Tempat_Bermain_Olahraga', 'After_Tempat_Bermain_Olahraga',
        'Before_Ruang_TU', 'After_Ruang_TU', 'Before_Ruang_Konseling', 'After_Ruang_Konseling',
        'Before_Ruang_OSIS', 'After_Ruang_OSIS', 'Before_Bangunan', 'After_Bangunan', 'Rombel'
    ]
    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)
    except IOError as e:
        print(f"FATAL: Gagal membuat file CSV {filename}. Error: {e}")
        sys.exit(1)


def append_to_csv(filename, school_data, school_name, province, kota, kecamatan):
    """Menambahkan data sekolah ke file CSV."""
    profile = school_data.get('profile', {})
    contact = school_data.get('contact', {})
    recapitulation = school_data.get('recapitulation', {}) 

    identitas = profile.get('identitas_sekolah', {})
    pelengkap = profile.get('data_pelengkap', {})
    rinci = profile.get('data_rinci', {})
    sidebar = profile.get('sidebar_info', {})

    # Perhitungan Total Rekapitulasi
    Guru_L = recapitulation.get('ptk_laki', 0)
    Guru_P = recapitulation.get('ptk_perempuan', 0)
    Guru_Total = Guru_L + Guru_P
    
    Tendik_L = recapitulation.get('pegawai_laki', 0)
    Tendik_P = recapitulation.get('pegawai_perempuan', 0)
    Tendik_Total = Tendik_L + Tendik_P
    
    PTK_L = recapitulation.get('ptk_laki', 0) + recapitulation.get('pegawai_laki', 0)
    PTK_P = recapitulation.get('ptk_perempuan', 0) + recapitulation.get('pegawai_perempuan', 0)
    PTK_Total = PTK_L + PTK_P
    
    PD_L = recapitulation.get('pd_laki', 0)
    PD_P = recapitulation.get('pd_perempuan', 0)
    PD_Total = PD_L + PD_P

    # --- MEMBANGUN BARIS CSV ---
    row = [
        school_name,province, kota, kecamatan,
        identitas.get('NPSN', ''), identitas.get('Status', ''), identitas.get('Bentuk Pendidikan', ''), identitas.get('Status Kepemilikan', ''),
        identitas.get('SK Pendirian Sekolah', ''), identitas.get('Tanggal SK Pendirian', ''), identitas.get('SK Izin Operasional', ''),
        identitas.get('Tanggal SK Izin Operasional', ''), pelengkap.get('Kebutuhan Khusus Dilayani', ''), pelengkap.get('Nama Bank', ''),
        pelengkap.get('Cabang KCP/Unit', ''), pelengkap.get('Rekening Atas Nama', ''), rinci.get('Status BOS', ''),
        rinci.get('Waku Penyelenggaraan', ''), rinci.get('Sertifikasi ISO', ''), rinci.get('Sumber Listrik', ''),
        rinci.get('Daya Listrik', ''), rinci.get('Kecepatan Internet', ''), sidebar.get('Kepsek', ''), sidebar.get('Operator', ''),
        sidebar.get('Akreditasi', ''), sidebar.get('Kurikulum', ''), sidebar.get('Waktu', ''), contact.get('Alamat', ''),
        contact.get('RT / RW', ''), contact.get('Dusun', ''), contact.get('Desa / Kelurahan', ''), contact.get('Kecamatan', ''),
        contact.get('Kabupaten', ''), contact.get('Provinsi', ''), contact.get('Kode Pos', ''), contact.get('Lintang', ''),
        contact.get('Bujur', ''), Guru_L, Guru_P, Guru_Total, Tendik_L, Tendik_P, Tendik_Total, PTK_L, PTK_P, PTK_Total,
        PD_L, PD_P, PD_Total, recapitulation.get('before_ruang_kelas', 0), recapitulation.get('after_ruang_kelas', 0),
        recapitulation.get('before_ruang_perpus', 0), recapitulation.get('after_ruang_perpus', 0),
        recapitulation.get('before_ruang_lab', 0), recapitulation.get('after_ruang_lab', 0),
        recapitulation.get('before_ruang_praktik', 0), recapitulation.get('after_ruang_praktik', 0),
        recapitulation.get('before_ruang_pimpinan', 0), recapitulation.get('after_ruang_pimpinan', 0),
        recapitulation.get('before_ruang_guru', 0), recapitulation.get('after_ruang_guru', 0),
        recapitulation.get('before_ruang_ibadah', 0), recapitulation.get('after_ruang_ibadah', 0),
        recapitulation.get('before_ruang_uks', 0), recapitulation.get('after_ruang_uks', 0),
        recapitulation.get('before_toilet', 0), recapitulation.get('after_toilet', 0),
        recapitulation.get('before_gudang', 0), recapitulation.get('after_gudang', 0),
        recapitulation.get('before_ruang_sirkulasi', 0), recapitulation.get('after_ruang_sirkulasi', 0),
        recapitulation.get('before_tempat_bermain_olahraga', 0), recapitulation.get('after_tempat_bermain_olahraga', 0),
        recapitulation.get('before_ruang_tu', 0), recapitulation.get('after_ruang_tu', 0),
        recapitulation.get('before_ruang_konseling', 0), recapitulation.get('after_ruang_konseling', 0),
        recapitulation.get('before_ruang_osis', 0), recapitulation.get('after_ruang_osis', 0),
        recapitulation.get('before_bangunan', 0), recapitulation.get('after_bangunan', 0), recapitulation.get('rombel', 0)
    ]

    try:
        with open(filename, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(row)
    except IOError as e:
        print(f"        [FATAL WRITE ERROR] Gagal menulis ke CSV: {e}")


# --- MAIN EXECUTION ---

def main():
    """Fungsi utama untuk menjalankan proses scraping interaktif."""
    
    start_time = time.time()
    
    # 1. Pilihan Provinsi
    print("--- ⚙️ Memulai Script Dapodik Scraper Interaktif ---")
    response_provinsi = request_api()
    if not response_provinsi:
        print("Gagal mengambil daftar Provinsi dari API Dapodik.")
        return

    print("\n--- DAFTAR PROVINSI ---")
    for i, prov in enumerate(response_provinsi):
        print(f"[{i}] {prov['nama']}")
    print("------------------------")
    
    try:
        prov_num_input = input(f"Masukkan nomor provinsi (0 sampai {len(response_provinsi)-1}) yang ingin di-scrape: ")
        prov_num = int(prov_num_input.strip())
        if not (0 <= prov_num < len(response_provinsi)):
            print("Nomor provinsi tidak valid.")
            return
    except ValueError:
        print("Input harus berupa angka.")
        return
        
    province_target = response_provinsi[prov_num]
    
    # 2. Pilihan Kota/Kabupaten
    provinsi_level = province_target['id_level_wilayah']
    provinsi_kode = province_target['kode_wilayah'].strip()

    response_kota = request_api(level_wilayah=provinsi_level, kode_wilayah=provinsi_kode, semester_id=SEMESTER_ID)
    
    if not response_kota:
        print(f"Gagal mengambil data Kota/Kabupaten untuk {province_target['nama']}.")
        return

    print(f"\n--- DAFTAR KOTA/KABUPATEN di {province_target['nama']} ---")
    
    # Tambahkan opsi untuk scrape semua
    semua_idx = len(response_kota)
    print(f"[{semua_idx}] SEMUA Kota/Kabupaten") 
    
    for i, kota in enumerate(response_kota):
        print(f"[{i}] {kota['nama']}")
    print("-----------------------------------------------------")
    
    try:
        kota_input = input(f"Masukkan nomor Kota/Kabupaten yang ingin di-scrape (0 sampai {semua_idx}), atau pisahkan dengan koma jika lebih dari satu: ")
        
        # Penentuan target Kota/Kabupaten
        if kota_input.strip() == str(semua_idx):
            kota_targets = response_kota
        else:
            selected_indices = [int(i.strip()) for i in kota_input.split(',')]
            
            kota_targets = []
            for idx in selected_indices:
                if 0 <= idx < len(response_kota):
                    kota_targets.append(response_kota[idx])
                else:
                    print(f"Nomor Kota/Kabupaten {idx} tidak valid. Diabaikan.")
            
            if not kota_targets:
                print("Tidak ada Kota/Kabupaten yang valid dipilih. Program dihentikan.")
                return

    except ValueError:
        print("Input tidak valid. Harap masukkan angka atau pisahkan dengan koma.")
        return
    
    
    # 3. Setup File dan Direktori
    output_dir = './result'
    os.makedirs(output_dir, exist_ok=True) 
    
    # Penamaan file CSV
    if len(kota_targets) == len(response_kota):
        file_suffix = "SEMUA"
    elif len(kota_targets) == 1:
        file_suffix = kota_targets[0]["nama"].replace(" ", "_").replace(".", "")
    else:
        # Jika memilih lebih dari 1 kota/kabupaten
        file_suffix = f"{len(kota_targets)}_KOTA"
        
    csv_filename = f'{output_dir}/{province_target["nama"].replace(" ", "_")}_{file_suffix}_data.csv'
    
    # Buat header CSV
    create_csv_header(csv_filename)
    print(f"\nCSV header berhasil dibuat di: {csv_filename}")
    
    # 4. Proses Scraping
    provinsi_nama = province_target['nama']

    print(f"\n--- Memulai Scraping {len(kota_targets)} Kota/Kabupaten di {provinsi_nama} ---")
    
    total_sekolah_sukses = 0

    for kota in kota_targets:
        print(f"\n  [DIPROSES] Kota: {kota['nama']}")
        kota_kode = kota['kode_wilayah'].strip()

        # Level 3: Kecamatan
        # Level wilayah untuk kota adalah '2', kita pakai '2' untuk mengambil data kecamatan
        response_kecamatan = request_api(level_wilayah='2', kode_wilayah=kota_kode, semester_id=SEMESTER_ID)
        
        if not response_kecamatan:
            print(f"  >>> Gagal mengambil data Kecamatan untuk {kota['nama']}")
            time.sleep(1)
            continue

        for kecamatan in response_kecamatan:
            print(f"    Kecamatan: {kecamatan['nama']}")
            
            # Kode wilayah untuk API sekolah (Level 4)
            # Level 4 API membutuhkan kode kecamatan + '&bentuk_pendidikan_id='
            kecamatan_kode_for_sekolah_api = kecamatan['kode_wilayah'].strip() + '&bentuk_pendidikan_id=' 
            
            # Level 4: Sekolah
            response_sekolah = request_api(level_wilayah='4', kode_wilayah=kecamatan_kode_for_sekolah_api, semester_id=SEMESTER_ID)
            
            if not response_sekolah:
                # Pesan error 404/500 sudah dicetak di request_api jika gagal, lalu langsung lanjut (Fast Fail)
                print(f"    >>> Gagal atau Tidak ada data sekolah ditemukan untuk {kecamatan['nama']} (Lanjut...)")
                time.sleep(0.5) 
                continue

            print(f"    >>> BERHASIL MENDAPATKAN {len(response_sekolah)} sekolah dari {kecamatan['nama']}.")
            
            # Filter Sekolah
            jenjang_target = ['SD', 'SMP', 'SMA', 'SPK SD', 'SPK SMP', 'SPK SMA', 'SMK']
            jenis_target = ['Negeri','Swasta']

            for sekolah in response_sekolah:
                if sekolah['bentuk_pendidikan'] in jenjang_target and sekolah['status_sekolah'] in jenis_target:
                    
                    sekolah_nama = sekolah['nama']
                    sekolah_id_enkrip = sekolah['sekolah_id_enkrip'].strip()
                    
                    print(f"      Sekolah: {sekolah_nama}")
                    
                    try:
                        # URL detail sekolah (HTML scraping)
                        school_url = f"https://dapo.dikdasmen.go.id/sekolah/{sekolah_id_enkrip}"
                        
                        school_detail_json = parse_html(school_url)
                        school_data = json.loads(school_detail_json)

                        append_to_csv(
                            csv_filename, 
                            school_data, 
                            sekolah_nama, 
                            provinsi_nama, 
                            kota['nama'], 
                            kecamatan['nama']
                        )
                        print(f"        [SUCCESS] Data {sekolah_nama} ditambahkan ke CSV.")
                        total_sekolah_sukses += 1
                        time.sleep(0.5) # Jeda sebentar antar sekolah
                        
                    except Exception as e:
                        print(f"        [ERROR] Gagal memproses detail sekolah {sekolah_nama}: {e}")
                        time.sleep(3) # Jeda lebih lama jika ada error saat scraping detail

    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n--- ✅ Proses Scraping Selesai ---")
    print(f"Total Sekolah Berhasil Diproses: {total_sekolah_sukses}")
    print(f"Data disimpan ke: {csv_filename}")
    print(f"Waktu Eksekusi Total: {elapsed_time:.2f} detik")


if __name__ == '__main__':
    main()